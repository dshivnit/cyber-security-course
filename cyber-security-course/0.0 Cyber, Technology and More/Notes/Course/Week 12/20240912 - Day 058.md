
---
- Web Scraping
	- A computer technique used to extract information from websites
	- Involves automatically fetching web pages, extracting data from them, and saving that data for various purposes. 
- lxml
	- Exists just for Python
	- There are other libraries for other languages
	- https://lxml.de/tutorial.html
	- Tree data structures
- xml
	- came after HTML
- Beautiful Soup
	- Allows you to pull data out of HTML and XML
	- https://www.crummy.com/software/BeautifulSoup/bs4/doc/
	- Running through the above but passing http://phrack.org into a requests.get("http://phrack.org") in python3
	- (make sure that requests is installed - pip install requests)
	- response = requests.get("http://phrack.org")
	- Then run through the above crummy.com 
- Scraping
	- Google would use Beautiful Soup to scrape through websites
	- Search engines in general scrape the heck out of all websites to be able to essentially search for them 
- Robots.txt
- Access to hidden APIs
- Python has a library called `scrapy`
	- Which has code for scraping stuff
	- https://scrapy.org/
	- https://toscrape.com/
	- https://quotes.toscrape.com/tag/humor/
		- Going through content in this page
		- Inspecting elements
		- div class > row
			- div class > quote
				- spans
					- To show the quote and the author
		- Combining these processes and these elements should be considered when writing a scraper
	- Keep note of general (commonly used) HTML tags that are used in websites
		- p, body, a (a href's for links to other sites) 
	- For the most part you'd have to analyse the website first and see what kind of structure/content they have in the site to be able to write a scraper script first
	- 
- Scapy
	- https://scapy.net/
	- Library for doing network related stuff in Python
	- "Powerful interactive packet manipulation library"
	- `scrapy startproject projectname`
		- Will get you a project directory which will have a config file and a subdir 
	- By default in settings.py the ua will be pointing to the project name
- ifconfig.me/ua
	- To get your own UA

- random Python stuff
	- If you have a function within a class
	- the first Function has to have it's first argument as "self" 
	- Example:
	```python
	class QuotesSpider(scrapy.Spider):
    name = "quotes"
    start_urls = [
        "https://quotes.toscrape.com/tag/humor/",
    ]

    def parse(self, response):
```
- Note the first argument in the parse function is `self`
- Self in Python:
	- What is SELF in Python? SELF represents the instance of class. This handy keyword allows you to access variables, attributes, and methods of a defined class in Python. (hubspot blog)
- 
---
- 
---
People:
- Tim Burners-Lee 
	- Invented HTML
---
Terms and Things:
- https://lxml.de/
- DOM
	- Document Object Module
- Absolute links
	- Full path to a link
- Relative links
	- example: `./directory/page.name`
- yield in python and in programming
	- similar to the return command but
		- Give back the data when it is next requested
			- lazy loading/requesting (look into this)
			- Data will only be returned when the script/code tells it to
- yield in programming (mainly Python)
- Python Generators
- URL Slug
	- Example:
		- https://www.lightnovelworld.co/novel/shadow-slave-05122222/chapters
		- the shadow-slave-05122222
	- To *slugify*
- 2>/dev/null
	- Consider throwing stderr to a debug file if needed, or whatever :) 
- 
---
ToDo:
- https://lxml.de/tutorial.html
- Do that scraping test you thought of with content that is only pulled from a db
	- Can content still be scraped before that query is run? Thinking so but give it a go for the sake of it
- Go through the pwn college stuff bruh
- Check out Scapy in more depth bruv
- https://www.datacamp.com/blog/top-python-libraries-for-data-science
	- Go through these when you ahve a chance
- Python Generators
	- Look into this when you can.
- Go through this when you can
	- https://docs.scrapy.org/en/latest/intro/tutorial.html
- Go through your own methods of identifying bots
- 